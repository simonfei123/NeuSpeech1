{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719b99e4940764b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.process_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 从原始的EEG信号中获取到每个session的时间，并对speech的时间进行检测冲突，获得可以使用的被试的数据。\n",
    "dataset_validation = 0\n",
    "dataset_validation_list = []\n",
    "processor = PreprocessorWithAudio()\n",
    "formal_data_root_dir = './formal_dataset'\n",
    "for number in tqdm(range(1, 101)):\n",
    "    formal_data_subject_root_dir = os.path.join(formal_data_root_dir, f'sub_{number}')\n",
    "    eeg_path = processor.get_eeg_path(number)\n",
    "    if eeg_path is None:\n",
    "        dataset_validation_list.append((number, -1))\n",
    "    else:\n",
    "        try:\n",
    "\n",
    "            audio_path_list = processor.get_audio_path(number)\n",
    "            processor.load_data(eeg_path)\n",
    "            processor.get_info(number)\n",
    "            # 保存原始数据 暂时不弄这个\n",
    "\n",
    "            orig_eeg = processor.raw.get_data()[:66]\n",
    "            orig_eeg_path = os.path.join(formal_data_root_dir, f'orig_eeg/orig_eeg_sub_{number}.npy')\n",
    "            os.makedirs(os.path.dirname(orig_eeg_path), exist_ok=True)\n",
    "            np.save(orig_eeg_path, orig_eeg)\n",
    "\n",
    "            processor.filter_data()\n",
    "            processor.fix_bads()\n",
    "            # 将处理好的数据保存起来\n",
    "            pro_eeg = processor.raw.get_data()[:66]\n",
    "            processed_eeg_path = os.path.join(formal_data_subject_root_dir, f'pro_eeg/pro_eeg_sub_{number}.npy')\n",
    "            os.makedirs(os.path.dirname(processed_eeg_path), exist_ok=True)\n",
    "            np.save(processed_eeg_path, pro_eeg)\n",
    "            # 保存info\n",
    "            processed_eeg_info_path = os.path.join(formal_data_subject_root_dir,\n",
    "                                                   f'pro_eeg/pro_eeg_info_sub_{number}.npy')\n",
    "            os.makedirs(os.path.dirname(processed_eeg_info_path), exist_ok=True)\n",
    "            np.save(processed_eeg_info_path, processor.info)\n",
    "            # 保存ch_names\n",
    "            processed_eeg_ch_names_path = os.path.join(formal_data_subject_root_dir,\n",
    "                                                       f'pro_eeg/pro_eeg_ch_names_sub_{number}.npy')\n",
    "            os.makedirs(os.path.dirname(processed_eeg_ch_names_path), exist_ok=True)\n",
    "            np.save(processed_eeg_ch_names_path, np.array(processor.raw.ch_names))\n",
    "\n",
    "            # 进入分割操作\n",
    "            validate = check_audio_eeg(processor.info, audio_path_list)\n",
    "            dataset_validation += validate\n",
    "            dataset_validation_list.append((number, validate))\n",
    "            sub_video_dict = {}\n",
    "            sub_speech_dict = {}\n",
    "            if validate == 1:\n",
    "                for seg_idx in range(8):\n",
    "                    formal_data_seg_root_dir = os.path.join(formal_data_subject_root_dir, f'seg_{seg_idx}')\n",
    "                    # 从脑电信号中得到分段的时间 audio\n",
    "                    seg_time_idx_s, seg_time_idx_e = get_audio_segment_from_idx(processor.info, seg_idx)\n",
    "                    audio_path = audio_path_list[seg_idx]\n",
    "                    waveform, sample_rate = sf.read(audio_path)\n",
    "                    waveform = waveform[:, 0]\n",
    "                    wave_sec = waveform.shape[0] / sample_rate\n",
    "                    # get the spoken eeg signal and save\n",
    "                    eeg_signal = pro_eeg[:, seg_time_idx_s:seg_time_idx_s + int(wave_sec * processor.eeg_sr)]\n",
    "                    processed_spoken_eeg_seg_path = os.path.join(formal_data_seg_root_dir,\n",
    "                                                                 f'eeg/sub_{number}_seg_{seg_idx}_spoken_eeg.npy')\n",
    "                    os.makedirs(os.path.dirname(processed_spoken_eeg_seg_path), exist_ok=True)\n",
    "                    np.save(processed_spoken_eeg_seg_path, eeg_signal)\n",
    "\n",
    "                    sub_speech_dict[seg_idx] = {\n",
    "                        'duration': wave_sec,\n",
    "                        'start_sec': seg_time_idx_s / processor.eeg_sr,\n",
    "                        'end_sec': seg_time_idx_s / processor.eeg_sr + wave_sec,\n",
    "                    }\n",
    "                    # get the audio signal and save\n",
    "                    processed_audio_path = os.path.join(formal_data_seg_root_dir,\n",
    "                                                        f'audio/sub_{number}_seg_{seg_idx}_audio.npy')\n",
    "                    os.makedirs(os.path.dirname(processed_audio_path), exist_ok=True)\n",
    "                    np.save(processed_audio_path, waveform)\n",
    "                    # 观看视频时的数据存储\n",
    "                    seg_watching_time_idx_s, seg_watching_time_idx_e = get_segment_from_idx(processor.info, seg_idx)\n",
    "                    eeg_watching_signal = pro_eeg[:, seg_watching_time_idx_s:seg_watching_time_idx_e]\n",
    "                    processed_watching_eeg_seg_path = os.path.join(formal_data_seg_root_dir,\n",
    "                                                                   f'eeg/sub_{number}_seg_{seg_idx}_watching_eeg.npy')\n",
    "                    os.makedirs(os.path.dirname(processed_watching_eeg_seg_path), exist_ok=True)\n",
    "                    np.save(processed_watching_eeg_seg_path, eeg_watching_signal)\n",
    "\n",
    "                    # 观看的视频名字\n",
    "                    video_duration, video_name = processor.get_watch_video_duration(number=number, seg_idx=seg_idx,\n",
    "                                                                                    return_video_name=True)\n",
    "                    sub_video_dict[seg_idx] = {\n",
    "                        'name': video_name,\n",
    "                        'duration': video_duration,\n",
    "                        'start_sec': seg_watching_time_idx_s / processor.eeg_sr,\n",
    "                        'end_sec': seg_watching_time_idx_e / processor.eeg_sr,\n",
    "                    }\n",
    "                # this is wrong, fix this and delete this.\n",
    "                # save meta data\n",
    "                meta_dict = {\n",
    "                    'ch_name': processor.raw.ch_names,\n",
    "                    'info': processor.info[:, 0].tolist(),\n",
    "                    'spoken_eeg_path': processed_spoken_eeg_seg_path,\n",
    "                    'audio_path': processed_audio_path,\n",
    "                    'watching_eeg_seg_path': processed_watching_eeg_seg_path,\n",
    "                    'video_name': sub_video_dict,\n",
    "                    'eeg_sr': processor.eeg_sr,\n",
    "                    'speech_sr': processor.audio_sr,\n",
    "                }\n",
    "                meta_output_path = os.path.join(formal_data_subject_root_dir, f'meta_info.json')\n",
    "                with open(meta_output_path, \"w\") as json_file:\n",
    "                    json.dump(meta_dict, json_file, indent=4, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            print(number, e)\n",
    "            traceback.print_exc()\n",
    "            print('\\n' * 2)\n",
    "            dataset_validation_list.append((number, 2))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 检查哪些被试的数据是可用的\n",
    "    \n",
    "valid_subject_list=[]\n",
    "for i,subject_number in tqdm(enumerate(range(1,101))):\n",
    "    seg_idx=0\n",
    "    try:\n",
    "        npy_path=f'formal_dataset/sub_{subject_number}/meta_info.json'\n",
    "        with open(npy_path,'r',encoding='utf8')as fp:\n",
    "            json_data = json.load(fp)\n",
    "        # print(subject_number)\n",
    "    except:\n",
    "        continue\n",
    "    valid_subject_list.append(subject_number)    \n",
    "print(len(valid_subject_list))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f80e5007894c585e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meta_output_path='formal_dataset/valid.json'\n",
    "meta_dict={\n",
    "    'valid_number':valid_subject_list,\n",
    "    'total_valid_number':len(valid_subject_list),\n",
    "}\n",
    "with open(meta_output_path, \"w\") as json_file:\n",
    "    json.dump(meta_dict, json_file, indent=4,ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d97b4fcde9e2b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meta_output_path='formal_dataset/valid.json'\n",
    "with open(meta_output_path, \"r\") as json_file:\n",
    "    meta_dict=json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1946cce4785c9f74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model=whisper.load_model('large',download_root='./whisper_models')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2449d85ac030433c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subject_list=meta_dict['valid_number']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3aad54cde54780b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 从音频转写到文本。还需要把音频转为16kHz，写入json文件\n",
    "for subject_number in tqdm(valid_subject_list):\n",
    "    for seg_idx in tqdm(range(8)):\n",
    "        npy_path=f'formal_dataset/sub_{subject_number}/seg_{seg_idx}/audio/sub_{subject_number}_seg_{seg_idx}_audio.npy'\n",
    "        signal=np.load(npy_path)\n",
    "        sample_rate=44100\n",
    "        new_sample_rate=16000\n",
    "        new_signal = librosa.resample(signal, orig_sr=sample_rate, target_sr=new_sample_rate)\n",
    "        # try:\n",
    "        #     os.remove(npy_path[:-4]+'.mp3')\n",
    "        #     print(\"文件已成功删除！\")\n",
    "        # except OSError as e:\n",
    "        #     print(\"删除文件时出现错误:\", e)\n",
    "        processed_audio_path=npy_path[:-4]+'16kHz.mp3'\n",
    "        sf.write(processed_audio_path, new_signal, new_sample_rate)\n",
    "        result = model.transcribe(\n",
    "            processed_audio_path,language=\"Chinese\",word_timestamps=True,\n",
    "            without_timestamps=False,initial_prompt='以下是简体中文的句子，每个句子只能有一个标点符号。')\n",
    "\n",
    "        # 写入文本\n",
    "        transcribe_path=f\"./transcribe/sub_{subject_number}/seg_{seg_idx}/transcribe_sub_{subject_number}_seg_{seg_idx}.json\"\n",
    "        transcribe_path=makedirs(transcribe_path)\n",
    "        with open(transcribe_path, 'w') as write_f:\n",
    "        \tjson.dump(result, write_f, indent=4, ensure_ascii=False)\n",
    "        with open(npy_path[:-3]+'json', 'w') as write_f:\n",
    "        \tjson.dump(result, write_f, indent=4, ensure_ascii=False)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae435ca1330612e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 统计有多少个词汇\n",
    "# calculate total vocabulary\n",
    "word_dict={}\n",
    "char_dict={}\n",
    "for subject_number in tqdm(valid_subject_list):\n",
    "    for seg_idx in range(8):\n",
    "        transcribe_path=f\"./transcribe/sub_{subject_number}/seg_{seg_idx}/transcribe_sub_{subject_number}_seg_{seg_idx}.json\"\n",
    "        with open(transcribe_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        text=data['text']\n",
    "        sententce_word_dict=stat_word_freq(text)\n",
    "        sententce_char_dict=stat_char_freq(text)\n",
    "        word_dict=merge_dicts(word_dict,sententce_word_dict)\n",
    "        char_dict=merge_dicts(char_dict,sententce_char_dict)\n",
    "print(len(word_dict),len(char_dict))        \n",
    "char_num=0\n",
    "for key in char_dict.keys():\n",
    "    char_num+=char_dict[key]\n",
    "print(char_num)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e83890d6d3b1589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 统计时长，语句数量，词汇数量，字数量。训练集和测试集的重叠数量。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e20552838d2389a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对已经正确的被试，只用word，先全部转为简体，根据标点符号分割句子，或者word太长重新成句。分割成30s以内的句子。\n",
    "time_limit=5\n",
    "speech_sr=16000\n",
    "eeg_sr=1000\n",
    "data_dict_list=[]\n",
    "output_root_dir='formal_dataset'\n",
    "output_folder=f'cut_seg{time_limit}s_singe_sentence'\n",
    "problematic_datas=[]\n",
    "try:\n",
    "    # 清空之前的文件\n",
    "    os.system(f'rm -rf {output_root_dir}/{output_folder}')\n",
    "except Exception as e:\n",
    "    pass\n",
    "for subject_number in tqdm(valid_subject_list):\n",
    "    data_dict_subject_list=[]\n",
    "    for seg_idx in range(8):\n",
    "        data_dict_seg_list=[]\n",
    "        transcribe_path=f\"./transcribe/sub_{subject_number}/seg_{seg_idx}/transcribe_sub_{subject_number}_seg_{seg_idx}.json\"\n",
    "        with open(transcribe_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        text=data['text']\n",
    "        segments=data['segments']\n",
    "        # print(f'text:{text}')\n",
    "        # if has_multiple_english_words(text):\n",
    "        #     print(f'sub_{subject_number}_seg_{seg_idx} has_multiple_english_words')\n",
    "        #     print(f'text:{text}')\n",
    "        #     print('='*40)\n",
    "        # if check_repeat_sentences(segments):    \n",
    "        #     # 如果有重复的句子，我就直接删掉之前的文件，并且跳过。\n",
    "        #     print(f'sub_{subject_number}_seg_{seg_idx}text:{text} has repeat sentences')\n",
    "        #     continue\n",
    "        status_has_multiple_english_words=has_multiple_english_words(text)\n",
    "        status_has_repeat_sentences=check_repeat_sentences(segments)\n",
    "        if status_has_multiple_english_words or status_has_repeat_sentences:\n",
    "            problematic_datas.append([\n",
    "                subject_number,\n",
    "                seg_idx,\n",
    "                text,\n",
    "                (status_has_multiple_english_words,status_has_repeat_sentences)\n",
    "            ])\n",
    "            continue\n",
    "            \n",
    "        words=[]\n",
    "        for sentence in segments:\n",
    "            word=sentence['words']\n",
    "            if len(word)>=1:\n",
    "                word[-1]['word']=check_chinese_punctuation(word[-1]['word'],chinese_punctuation = '[,.?，。？]')\n",
    "            # 如果最后一个词没有标点符号，就加句号。\n",
    "            words.extend(word)\n",
    "        # 从单词分成句子。\n",
    "        new_sentences=combine_words_to_sentences_within_time_limit(words,time_limit=time_limit-0.1)\n",
    "        # print('after combine_sentences')\n",
    "        # print(new_sentences)\n",
    "\n",
    "        # 根据时间限制分段\n",
    "        # new_sentences_combination=combine_sentences_within_time_limit(new_sentences,time_limit)\n",
    "        new_sentences_combination=combine_single_sentences(new_sentences)\n",
    "        # print('after combine_sentences_within_time_limit')\n",
    "        # print(new_sentences_combination)\n",
    "        new_sentences_combination=combinations_to_data_dict(new_sentences_combination)\n",
    "        # print('after combinations_to_data_dict')\n",
    "        # print(new_sentences_combination)\n",
    "        # 写入音频和EEG。并且写jsonlines\n",
    "\n",
    "        # speech和EEG存放位置\n",
    "        orig_eeg_path=f'{output_root_dir}/sub_{subject_number}/seg_{seg_idx}/eeg/sub_{subject_number}_seg_{seg_idx}_spoken_eeg.npy'\n",
    "        orig_speech_path=f'{output_root_dir}/sub_{subject_number}/seg_{seg_idx}/audio/sub_{subject_number}_seg_{seg_idx}_audio16kHz.mp3'\n",
    "             \n",
    "        waveform, sample_rate = sf.read(orig_speech_path)\n",
    "        assert len(waveform.shape)==1\n",
    "        eeg=np.load(orig_eeg_path)\n",
    "        assert eeg.shape[0]<eeg.shape[1], '通道数肯定会小于EEG文件的长度'\n",
    "        \n",
    "        for comb_idx,comb in enumerate(new_sentences_combination):\n",
    "            # 控制起止时间和位置\n",
    "            start=comb['start']\n",
    "            end=comb['end']\n",
    "            if end-start>29 or end-start<0.2:\n",
    "                print(f'subject{subject_number} seg_idx{seg_idx} comb_idx{comb_idx} is too long'\n",
    "                       f'duration is {np.round(end-start,2)}s, comb is {comb}')\n",
    "            start_speech=int(start*speech_sr)\n",
    "            start_eeg=int(start*eeg_sr)\n",
    "            end_speech=int(end*speech_sr)\n",
    "            end_eeg=int(end*eeg_sr)\n",
    "            \n",
    "            # 控制路径\n",
    "            new_eeg_path=f'{output_root_dir}/{output_folder}/sub_{subject_number}/seg_{seg_idx}/eeg/sub_{subject_number}_seg_{seg_idx}_cut_{comb_idx}_spoken_eeg.npy'\n",
    "            makedirs(new_eeg_path)\n",
    "            new_speech_path=f'{output_root_dir}/{output_folder}/sub_{subject_number}/seg_{seg_idx}/speech/sub_{subject_number}_seg_{seg_idx}_cut_{comb_idx}_spoken_speech.mp3'\n",
    "            makedirs(new_speech_path)\n",
    "            # 切分音频和EEG\n",
    "            cut_audio=waveform[start_speech:end_speech]\n",
    "            cut_eeg=eeg[:,start_eeg:end_eeg]\n",
    "            # 写入音频和EEG\n",
    "            sf.write(new_speech_path,cut_audio,speech_sr)\n",
    "            np.save(new_eeg_path,cut_eeg)\n",
    "            \n",
    "            # 生成json字典，安排地址，重新计算时间\n",
    "            new_start=0\n",
    "            new_end=end-start\n",
    "            data_dict={\n",
    "               \"speech\": {\n",
    "                  \"path\": new_speech_path\n",
    "               },\n",
    "               \"eeg\": {\n",
    "                  \"path\": new_eeg_path\n",
    "               },\n",
    "               \"sentence\": comb['sentence'],\n",
    "               \"language\": \"Chinese\",\n",
    "               \"sentences\": correct_timing(comb['sentences']),\n",
    "               \"duration\": comb['duration']\n",
    "            }\n",
    "            data_dict_seg_list.append(data_dict)\n",
    "            data_dict_subject_list.append(data_dict)\n",
    "            data_dict_list.append(data_dict)\n",
    "        if len(data_dict_seg_list)>0:\n",
    "            write_jsonlines(f'{output_root_dir}/{output_folder}/sub_{subject_number}/seg_{seg_idx}/sub_{subject_number}_seg_{seg_idx}.jsonl',data_dict_seg_list)\n",
    "        else:\n",
    "            problematic_datas.append([\n",
    "                subject_number,\n",
    "                seg_idx,\n",
    "                text,\n",
    "                (2,2)\n",
    "            ])\n",
    "        \n",
    "# print(data_dict)            \n",
    "write_jsonlines(f'{output_root_dir}/{output_folder}/all_data.jsonl', data_dict_list)\n",
    "# 数据处理完毕"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9080b01055c4a294"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "write_jsonlines(f'{output_root_dir}/{output_folder}/all_wrong_data.jsonl', problematic_datas)\n",
    "# 43个有错的seg，先不管了，数据够了。\n",
    "# 保存一下错误数据，之后方便修正数据。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44bfc75cf2cd5f34"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d7856a8162a8f19b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对数据进行打乱并切分\n",
    "\n",
    "import numpy as np\n",
    "json_dicts=read_jsonlines(f'{output_root_dir}/{output_folder}/all_data.jsonl')\n",
    "np.random.shuffle(json_dicts)\n",
    "all_num=len(json_dicts)\n",
    "train_num=int(0.8*all_num)\n",
    "val_num=int(0.9*all_num)\n",
    "train_json_dicts=json_dicts[:train_num]\n",
    "val_json_dicts=json_dicts[train_num:val_num]\n",
    "test_json_dicts=json_dicts[val_num:]\n",
    "write_jsonlines(f\"{output_root_dir}/{output_folder}/train_data.jsonl\",train_json_dicts)\n",
    "write_jsonlines(f\"{output_root_dir}/{output_folder}val_data.jsonl\",val_json_dicts)\n",
    "write_jsonlines(f\"{output_root_dir}/{output_folder}/test_data.jsonl\",test_json_dicts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fcff3ee8bfe22b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_duration=0\n",
    "for i in range(len(data_dict_list)):\n",
    "    all_duration=all_duration+data_dict_list[i]['duration']\n",
    "print(all_duration/3600)\n",
    "# 粗略的处理之后还剩 12.283661111111154个小时。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "284a9be93463bbfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 提取一个人的数据\n",
    "subject_id=1\n",
    "sub_jsonl=[]\n",
    "for i in range(8):\n",
    "    jsonl_path=f\"/home/yyang/dataset/multi_media/formal_dataset/cut_seg10s_singe_sentence/sub_1/seg_{i}/sub_1_seg_{i}.jsonl\"\n",
    "    try:\n",
    "        jsonl_data=read_jsonlines(jsonl_path)\n",
    "        sub_jsonl.extend(jsonl_data)\n",
    "        print(f'successfully add seg {i}')\n",
    "    except FileNotFoundError as e:\n",
    "        raise e \n",
    "print(len(sub_jsonl))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "904cf9248b971735"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
